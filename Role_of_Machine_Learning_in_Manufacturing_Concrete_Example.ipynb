{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "076f8b7e-cdca-41f5-95c1-2ccfe7ffa0ce",
   "metadata": {},
   "source": [
    "## Loading and preparing the data\n",
    "### Loading the Excel data\n",
    "The concrete strength data set is saved in an Excel Workbook. We can use the `read_excel` function of the `pandas` library to load the data as a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911a503d-d9a7-41a2-b807-a1f4a982f06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_excel(\"Concrete_Data.xls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c396534-8d5e-4aff-a4b1-05f3c180f858",
   "metadata": {},
   "source": [
    "By calling the \"head\" method of the loaded dataframe, we can examine the structure with regard to the first rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bd8e98-522a-47ba-a273-280d34c7460b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcefb8a-1259-465e-a8b0-d96415707c99",
   "metadata": {},
   "source": [
    "### Splitting the data by explanatory variables and outcome variable\n",
    "The first eight columns contain our explanatory variables which we want to use to **predict the outcome for concrete strength** (dependent variable), listed in the last column. To use this data as part of our regression models, we need to split it into the data on **independent variables** and the data on the **outcome variable**.\n",
    "\n",
    "For this purpose, we utilize the `iloc` method which allows us to slice rows and columns by their integer position, allowing selection of specific ranges or individual elements based on their index location. The first part of the argument before the comma indicates we want to select all rows whereas the second part indicates column selection. For our X data, we select all columns excluding the last column (half-open range). For our Y data, we select only the last column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ed319e-1bc5-40c6-86e9-56ce6a0b3d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = data.iloc[:, 0:8], data.iloc[:, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704d3199-ab15-4984-a037-cd8a95e59868",
   "metadata": {},
   "source": [
    "### Creating a train-test split\n",
    "To obtain a fair evaluate of the model's performance, we split the observations into training and test data. We use the latter to evaluate the trained model on unseen data.\n",
    "\n",
    "We can easily split the data using the `train_test_split` function from the `sklearn` library. The function splits the rows according to our specification of the relative share of training and test data.\n",
    "\n",
    "Here, we use 80% of our observations as training data and 20% for evaluation purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16def7c1-958e-4835-80ac-f2391a4303ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.80, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c685cf-bc92-4a61-a6a9-ec65f077aae0",
   "metadata": {},
   "source": [
    "### Normalizing the data of the dependent variables\n",
    "We normalize the features to ensure all data is on a similar scale. We can use the `MinMaxScaler` for this task which automatically rescales our feature data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d675d6-985f-4aa9-8588-b29bb4a247ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ab8617-f024-4451-a851-a516dccbc2ea",
   "metadata": {},
   "source": [
    "## Linear Regression Model\n",
    "First, we fit a linear regression model as a baseline. We use the `keras` library which provides an easy way to build an run machine learning models in Python 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd63f7d-b1ec-460e-84f2-7a901bac25fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d85a061-927d-4fb3-bf30-9b49c15f6e8a",
   "metadata": {},
   "source": [
    "### Building the linear regression model in `keras`\n",
    "The following code sets up a `Sequential` model for keras. We add a single layer where all explanatory variables (X) are directly connected to the single outcome variable (Y), modeling the typical structure of a linear regression model. \n",
    "\n",
    "Note that we use `keras` for the linear regression model and machine learning model to achieve consistency. Typically, you would fit the regression model using ordinary least squares. For our purpose here, the result will be the same.\n",
    "\n",
    "# INSERT IMAGE OF NETWORK STRUCTURE FROM LECTURE HERE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9392626b-9108-4a73-bf89-023817512505",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression = Sequential()\n",
    "linear_regression.add(Dense(1, activation='linear'))\n",
    "linear_regression.compile(optimizer=\"SGD\", loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c66f255-d2db-412f-9256-15e1aa5630ce",
   "metadata": {},
   "source": [
    "### Fitting the linear regression model\n",
    "To start the training and fit our model, we simply call the `fit` method, specifying the data as well as the number of iterations (epochs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd9bfd3-16e6-4b1d-a6f7-a90ad9880073",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression.fit(X_train, Y_train, epochs=1000, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a604f3-3fb1-4381-a192-d782b59432a9",
   "metadata": {},
   "source": [
    "# Deep Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c221f6-51d5-41ec-b4ca-12c8661732d6",
   "metadata": {},
   "source": [
    "### Building the deep neural network in `keras`\n",
    "The following code sets up a Sequential model for keras. We first add a dense layer with 64 neurons and ReLU activation, followed by another dense layer with 32 neurons and ReLU activation, modeling a deep neural network structure. The final layer is a single neuron with linear activation to produce a continuous output for the regression task.\n",
    "\n",
    "We compile the model using the Adam optimizer and mean squared error loss function to fit the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac868dd-173d-4e26-9818-32519f0aa602",
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network = Sequential()\n",
    "neural_network.add(Dense(64, activation='relu'))\n",
    "neural_network.add(Dense(32, activation='relu'))\n",
    "neural_network.add(Dense(1, activation='linear'))\n",
    "neural_network.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d5fdd1-7592-4aca-b223-edf5a20b072c",
   "metadata": {},
   "source": [
    "### Fitting the deep neural network model\n",
    "Next, we fit the neural network by calling the `fit` method. The batch size specifies the number of observations processed before updating the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4eee98-ede0-4c8e-82cb-fc66ae8b2f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network.fit(X_train, Y_train, epochs=1000, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ec166f-e977-4884-8598-b8fa53726fa6",
   "metadata": {},
   "source": [
    "## Evaluating the model performance\n",
    "For this purpose, we will utilize the following measures:\n",
    "\n",
    "### Mean Squared Error (MSE)\n",
    "$\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$\n",
    "\n",
    "### R-squared (RÂ²)\n",
    "$R^2 = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb3565f-fb49-4685-b304-3ec480589152",
   "metadata": {},
   "source": [
    "First, we apply each of the fitted models to the test set to obtain predictions for the concrete strength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85839d2c-854e-43b6-8356-1428e049531b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_lr = linear_regression.predict(X_test).flatten()\n",
    "Y_nn = neural_network.predict(X_test).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d019b2-aadb-430a-8acc-26177ffe2e67",
   "metadata": {},
   "source": [
    "Then, we can use the predictions to calculate the performance measures based on the predictions and actual concrete strength observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfa21aa-9b6f-42b8-b411-93ed9785ff48",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_lr = ((Y_test - Y_lr) ** 2).mean()\n",
    "r2_lr = 1 - mse_lr / ((Y_test - Y_test.mean()) ** 2).mean()\n",
    "\n",
    "mse_nn = ((Y_test - Y_nn) ** 2).mean()\n",
    "r2_nn = 1 - mse_nn / ((Y_test - Y_test.mean()) ** 2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ee797b-df23-431a-b3f2-b885286c80a7",
   "metadata": {},
   "source": [
    "Looking at the performance metrics, it becomes clear that the neural network model is able to explain a much higher fraction of the variation in concrete strength based on the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf220f0b-f962-4579-8627-1313db0bdb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{'Metric':<25} {'Linear Regression':<20} {'Neural Network'}\")\n",
    "print(f\"{'Mean Squared Error':<25} {mse_lr:<20} {mse_nn}\")\n",
    "print(f\"{'R-squared':<25} {r2_lr:<20} {r2_nn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6e29a9-2771-4a8b-be78-36321f796e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Linear Regression\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(Y_test, Y_lr, alpha=0.6)\n",
    "plt.plot([Y_test.min(), Y_test.max()], [Y_test.min(), Y_test.max()], 'r--')\n",
    "plt.xlabel('Actual concrete compressive strength (MPa)')\n",
    "plt.ylabel('Predicted concrete compressive strength (MPa)')\n",
    "plt.title('Linear Regression')\n",
    "\n",
    "# Neural Network\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(Y_test, Y_nn, alpha=0.6)\n",
    "plt.plot([Y_test.min(), Y_test.max()], [Y_test.min(), Y_test.max()], 'r--')\n",
    "plt.xlabel('Actual concrete compressive strength (MPa)')\n",
    "plt.ylabel('Predicted concrete compressive strength (MPa)')\n",
    "plt.title('Neural Network')\n",
    "plt.savefig(\"fit.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd90844-e60a-4a57-ae32-27eed47f48a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
